{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import random_split, DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel, default_data_collator\n",
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–°–æ–±–µ—Ä–µ–º –Ω–∞—à –¥–∞—Ç–∞—Å–µ—Ç –∏–∑ –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102282, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df1 = pd.read_csv('anno_first.csv')\n",
    "#df2 = pd.read_csv('anno_second.csv')\n",
    "df3 = pd.read_csv('anno_basketball.csv')\n",
    "df4 = pd.read_csv('anno_fiba.csv')\n",
    "df5 = pd.read_csv('anno_ncaa.csv')\n",
    "df = pd.concat([df3, df4, df5], axis=0)\n",
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–†–∞–∑–æ–±—å–µ–º –¥–∞—Ç–∞—Å–µ—Ç –Ω–∞ train test –∏ eval —á–∞—Å—Ç–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_df, eval_df = train_test_split(df, test_size=0.2)\n",
    "train_df, test_df = train_test_split(diff_df, test_size=0.2)\n",
    "# we reset the indices to start from zero\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "eval_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IAMDataset(Dataset):\n",
    "    def __init__(self, root_dir, df, processor, max_target_length=3):\n",
    "        self.root_dir = root_dir\n",
    "        self.df = df\n",
    "        self.processor = processor\n",
    "        self.max_target_length = max_target_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "      \n",
    "        file_name = self.df['file_name'][idx]\n",
    "        text = str(self.df['text'][idx])\n",
    "        #print(type(text))\n",
    "   \n",
    "        image = Image.open(file_name).convert(\"RGB\")\n",
    "        image = image.resize((64, 64))\n",
    "        pixel_values = self.processor(image, return_tensors=\"pt\").pixel_values\n",
    "        # add labels (input_ids) by encoding the text\n",
    "        labels = self.processor.tokenizer(text, \n",
    "                                          padding=\"max_length\", \n",
    "                                          max_length=self.max_target_length).input_ids\n",
    "        # important: make sure that PAD tokens are ignored by the loss function\n",
    "        labels = [label if label != self.processor.tokenizer.pad_token_id else -100 for label in labels]\n",
    "\n",
    "        encoding = {\"pixel_values\": pixel_values.squeeze(), \"labels\": torch.tensor(labels)}\n",
    "        return encoding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–°–æ–∑–¥–∞–¥–∏–º –Ω–∞—à–∏ –¥–∞—Ç–∞—Å–µ—Ç—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrOCRProcessor\n",
    "\n",
    "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
    "train_dataset = IAMDataset(root_dir='C:\\\\Users\\\\Mytre\\\\OneDrive\\\\–î–æ–∫—É–º–µ–Ω—Ç—ã\\\\Data\\\\Work\\\\',\n",
    "                           df=train_df,\n",
    "                           processor=processor)\n",
    "test_dataset = IAMDataset(root_dir='C:\\\\Users\\\\Mytre\\\\OneDrive\\\\–î–æ–∫—É–º–µ–Ω—Ç—ã\\\\Data\\\\Work\\\\',\n",
    "                           df=test_df,\n",
    "                           processor=processor)\n",
    "eval_dataset = IAMDataset(root_dir='C:\\\\Users\\\\Mytre\\\\OneDrive\\\\–î–æ–∫—É–º–µ–Ω—Ç—ã\\\\Data\\\\Work\\\\',\n",
    "                           df=test_df,\n",
    "                           processor=processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 65460\n",
      "Number of testing examples: 16365\n",
      "Number of validation examples: 16365\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of training examples:\", len(train_dataset))\n",
    "print(\"Number of testing examples:\", len(test_dataset))\n",
    "print(\"Number of validation examples:\", len(test_dataset))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ó–∞–≥—Ä—É–∑–∏–º –ø—Ä–µ–¥—ä–æ–±—É—á–µ–Ω–Ω—ã–π —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-stage1 and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-stage1\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–°–∫–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä—É–µ–º –Ω–∞—à—É –º–æ–¥–µ–ª—å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set special tokens used for creating the decoder_input_ids from the labels\n",
    "model.config.decoder_start_token_id = processor.tokenizer.cls_token_id\n",
    "model.config.pad_token_id = processor.tokenizer.pad_token_id\n",
    "# make sure vocab size is set correctly\n",
    "model.config.vocab_size = model.config.decoder.vocab_size\n",
    "\n",
    "# set beam search parameters\n",
    "model.config.eos_token_id = processor.tokenizer.sep_token_id\n",
    "model.config.max_length = 4\n",
    "model.config.early_stopping = True\n",
    "model.config.no_repeat_ngram_size = 3\n",
    "model.config.length_penalty = 2.0\n",
    "model.config.num_beams = 10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–°–∫–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä—É–µ–º —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    predict_with_generate=True,\n",
    "    num_train_epochs=10,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_train_batch_size=3,\n",
    "    per_device_eval_batch_size=3,\n",
    "    fp16=True, \n",
    "    output_dir=\"./\",\n",
    "    logging_steps=4000,\n",
    "    save_steps=40000,\n",
    "    eval_steps=20000,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–æ–ø—Ä–µ–¥–µ–ª–∏–º –º–µ—Ç—Ä–∏–∫—É"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mytre\\AppData\\Local\\Temp\\ipykernel_18136\\152175726.py:3: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ü§ó Evaluate: https://huggingface.co/docs/evaluate\n",
      "  cer_metric = load_metric(\"cer\")\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "cer_metric = load_metric(\"cer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels_ids = pred.label_ids\n",
    "    pred_ids = pred.predictions\n",
    "\n",
    "    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    labels_ids[labels_ids == -100] = processor.tokenizer.pad_token_id\n",
    "    label_str = processor.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "\n",
    "    cer = cer_metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"cer\": cer}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–∏–º –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=0.001, weight_decay=0.01, no_deprecation_warning=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ó–∞–ø—É—Å—Ç–∏–º —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    tokenizer=processor.feature_extractor,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    data_collator=default_data_collator,\n",
    ")\n",
    "trainer.train()\n",
    "\n",
    "model.save_pretrained('./model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ù–æ–º–µ—Ä –Ω–∞ —Ñ—É—Ç–±–æ–ª–∫–µ: 8\n"
     ]
    }
   ],
   "source": [
    "url = \"crops\\\\8\\\\ballerTV_137example.jpg\"\n",
    "image = Image.open(url).convert(\"RGB\")\n",
    "\n",
    "pixel_values = processor(image, return_tensors=\"pt\").pixel_values\n",
    "generated_ids = model.generate(pixel_values.cuda())\n",
    "\n",
    "generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "print(f'–ù–æ–º–µ—Ä –Ω–∞ —Ñ—É—Ç–±–æ–ª–∫–µ: {generated_text}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–ø—Ä–µ–¥–µ–ª–∏–º eval_dataloader –∏ –ó–∞–≥—Ä—É–∑–∏–º –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataloader = DataLoader(eval_dataset, batch_size=32)\n",
    "model = VisionEncoderDecoderModel.from_pretrained('model')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ—Å—á–∏—Ç–∞–µ–º —Ç–æ—á–Ω–æ—Å—Ç—å –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ eval –¥–∞—Ç–∞—Å–µ—Ç–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49fa8d9f120c45da9e9c5441aa61e640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mytre\\OneDrive\\–î–æ–∫—É–º–µ–Ω—Ç—ã\\Data\\Work\\workenv\\lib\\site-packages\\transformers\\generation\\utils.py:1288: UserWarning: Using `max_length`'s default (4) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [3] at entry 0 and [4] at entry 21",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m y_pred \u001b[39m=\u001b[39m []\n\u001b[0;32m     13\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m---> 14\u001b[0m     \u001b[39mfor\u001b[39;00m i, batch \u001b[39min\u001b[39;00m tqdm(\u001b[39menumerate\u001b[39m(eval_dataloader)):\n\u001b[0;32m     15\u001b[0m         \u001b[39m#url = eval_df['file_name'][i]\u001b[39;00m\n\u001b[0;32m     16\u001b[0m         target_text \u001b[39m=\u001b[39m processor\u001b[39m.\u001b[39mbatch_decode(batch[\u001b[39m'\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m'\u001b[39m], skip_special_tokens\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     17\u001b[0m         \u001b[39m#image = Image.open(url).convert(\"RGB\")        \u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Mytre\\OneDrive\\–î–æ–∫—É–º–µ–Ω—Ç—ã\\Data\\Work\\workenv\\lib\\site-packages\\tqdm\\notebook.py:259\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    258\u001b[0m     it \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m(tqdm_notebook, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__iter__\u001b[39m()\n\u001b[1;32m--> 259\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m it:\n\u001b[0;32m    260\u001b[0m         \u001b[39m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[0;32m    261\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[0;32m    262\u001b[0m \u001b[39m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Mytre\\OneDrive\\–î–æ–∫—É–º–µ–Ω—Ç—ã\\Data\\Work\\workenv\\lib\\site-packages\\tqdm\\std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1192\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[0;32m   1194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1195\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[0;32m   1196\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[0;32m   1197\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1198\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Mytre\\OneDrive\\–î–æ–∫—É–º–µ–Ω—Ç—ã\\Data\\Work\\workenv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Mytre\\OneDrive\\–î–æ–∫—É–º–µ–Ω—Ç—ã\\Data\\Work\\workenv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    673\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\Mytre\\OneDrive\\–î–æ–∫—É–º–µ–Ω—Ç—ã\\Data\\Work\\workenv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:61\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 61\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[1;32mc:\\Users\\Mytre\\OneDrive\\–î–æ–∫—É–º–µ–Ω—Ç—ã\\Data\\Work\\workenv\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    205\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[39m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[39m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[39m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m     \u001b[39mreturn\u001b[39;00m collate(batch, collate_fn_map\u001b[39m=\u001b[39;49mdefault_collate_fn_map)\n",
      "File \u001b[1;32mc:\\Users\\Mytre\\OneDrive\\–î–æ–∫—É–º–µ–Ω—Ç—ã\\Data\\Work\\workenv\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:128\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, collections\u001b[39m.\u001b[39mabc\u001b[39m.\u001b[39mMapping):\n\u001b[0;32m    127\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 128\u001b[0m         \u001b[39mreturn\u001b[39;00m elem_type({key: collate([d[key] \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m batch], collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m elem})\n\u001b[0;32m    129\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    130\u001b[0m         \u001b[39m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[0;32m    131\u001b[0m         \u001b[39mreturn\u001b[39;00m {key: collate([d[key] \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m batch], collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m elem}\n",
      "File \u001b[1;32mc:\\Users\\Mytre\\OneDrive\\–î–æ–∫—É–º–µ–Ω—Ç—ã\\Data\\Work\\workenv\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:128\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, collections\u001b[39m.\u001b[39mabc\u001b[39m.\u001b[39mMapping):\n\u001b[0;32m    127\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 128\u001b[0m         \u001b[39mreturn\u001b[39;00m elem_type({key: collate([d[key] \u001b[39mfor\u001b[39;49;00m d \u001b[39min\u001b[39;49;00m batch], collate_fn_map\u001b[39m=\u001b[39;49mcollate_fn_map) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m elem})\n\u001b[0;32m    129\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    130\u001b[0m         \u001b[39m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[0;32m    131\u001b[0m         \u001b[39mreturn\u001b[39;00m {key: collate([d[key] \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m batch], collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m elem}\n",
      "File \u001b[1;32mc:\\Users\\Mytre\\OneDrive\\–î–æ–∫—É–º–µ–Ω—Ç—ã\\Data\\Work\\workenv\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:120\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39mif\u001b[39;00m collate_fn_map \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    119\u001b[0m     \u001b[39mif\u001b[39;00m elem_type \u001b[39min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 120\u001b[0m         \u001b[39mreturn\u001b[39;00m collate_fn_map[elem_type](batch, collate_fn_map\u001b[39m=\u001b[39;49mcollate_fn_map)\n\u001b[0;32m    122\u001b[0m     \u001b[39mfor\u001b[39;00m collate_type \u001b[39min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    123\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32mc:\\Users\\Mytre\\OneDrive\\–î–æ–∫—É–º–µ–Ω—Ç—ã\\Data\\Work\\workenv\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:163\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    161\u001b[0m     storage \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39mstorage()\u001b[39m.\u001b[39m_new_shared(numel, device\u001b[39m=\u001b[39melem\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m    162\u001b[0m     out \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39mnew(storage)\u001b[39m.\u001b[39mresize_(\u001b[39mlen\u001b[39m(batch), \u001b[39m*\u001b[39m\u001b[39mlist\u001b[39m(elem\u001b[39m.\u001b[39msize()))\n\u001b[1;32m--> 163\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mstack(batch, \u001b[39m0\u001b[39;49m, out\u001b[39m=\u001b[39;49mout)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [3] at entry 0 and [4] at entry 21"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the device to run the evaluation on\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "model.to(device)\n",
    "# Evaluate the model on the eval dataset\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batch in tqdm(enumerate(eval_dataloader)):\n",
    "        #url = eval_df['file_name'][i]\n",
    "        target_text = processor.batch_decode(batch['labels'], skip_special_tokens=True)\n",
    "        #image = Image.open(url).convert(\"RGB\")        \n",
    "        pixel_values = batch['pixel_values']\n",
    "        generated_ids = model.generate(pixel_values.cuda())       \n",
    "\n",
    "        # Make a prediction\n",
    "        generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "\n",
    "        x = [] \n",
    "        for j in generated_text:       \n",
    "            if j.isdigit():\n",
    "                x.append(int(j))\n",
    "            else:\n",
    "                x.append(1000)        \n",
    "\n",
    "        # Save the true and predicted labels\n",
    "        y_true.append(target_text)\n",
    "        y_pred.append(x)  \n",
    "\n",
    "        if (i % 100  == 0) & (i > 2):\n",
    "            accuracy = accuracy_score(y_true, y_pred)\n",
    "            print(\"Accuracy:\", accuracy) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ—Å—á–∏—Ç–∞–µ–º —Ç–æ—á–Ω–æ—Å—Ç—å –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ eval –¥–∞—Ç–∞—Å–µ—Ç–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7daab55ecc14caa945f42ef47366ab2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16365 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9276807980049875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mytre\\OneDrive\\–î–æ–∫—É–º–µ–Ω—Ç—ã\\Data\\Work\\workenv\\lib\\site-packages\\transformers\\generation\\utils.py:1288: UserWarning: Using `max_length`'s default (4) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9176029962546817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mytre\\OneDrive\\–î–æ–∫—É–º–µ–Ω—Ç—ã\\Data\\Work\\workenv\\lib\\site-packages\\transformers\\generation\\utils.py:1288: UserWarning: Using `max_length`'s default (4) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9175686927560366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mytre\\OneDrive\\–î–æ–∫—É–º–µ–Ω—Ç—ã\\Data\\Work\\workenv\\lib\\site-packages\\transformers\\generation\\utils.py:1288: UserWarning: Using `max_length`'s default (4) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9131792629606496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mytre\\OneDrive\\–î–æ–∫—É–º–µ–Ω—Ç—ã\\Data\\Work\\workenv\\lib\\site-packages\\transformers\\generation\\utils.py:1288: UserWarning: Using `max_length`'s default (4) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9180409795102449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mytre\\OneDrive\\–î–æ–∫—É–º–µ–Ω—Ç—ã\\Data\\Work\\workenv\\lib\\site-packages\\transformers\\generation\\utils.py:1288: UserWarning: Using `max_length`'s default (4) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9150354019158684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mytre\\OneDrive\\–î–æ–∫—É–º–µ–Ω—Ç—ã\\Data\\Work\\workenv\\lib\\site-packages\\transformers\\generation\\utils.py:1288: UserWarning: Using `max_length`'s default (4) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9143163156015709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mytre\\OneDrive\\–î–æ–∫—É–º–µ–Ω—Ç—ã\\Data\\Work\\workenv\\lib\\site-packages\\transformers\\generation\\utils.py:1288: UserWarning: Using `max_length`'s default (4) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9150265542018119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mytre\\OneDrive\\–î–æ–∫—É–º–µ–Ω—Ç—ã\\Data\\Work\\workenv\\lib\\site-packages\\transformers\\generation\\utils.py:1288: UserWarning: Using `max_length`'s default (4) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.914745903915579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mytre\\OneDrive\\–î–æ–∫—É–º–µ–Ω—Ç—ã\\Data\\Work\\workenv\\lib\\site-packages\\transformers\\generation\\utils.py:1288: UserWarning: Using `max_length`'s default (4) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9137715571107223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mytre\\OneDrive\\–î–æ–∫—É–º–µ–Ω—Ç—ã\\Data\\Work\\workenv\\lib\\site-packages\\transformers\\generation\\utils.py:1288: UserWarning: Using `max_length`'s default (4) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.913883208361736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mytre\\OneDrive\\–î–æ–∫—É–º–µ–Ω—Ç—ã\\Data\\Work\\workenv\\lib\\site-packages\\transformers\\generation\\utils.py:1288: UserWarning: Using `max_length`'s default (4) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.911685065611331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mytre\\OneDrive\\–î–æ–∫—É–º–µ–Ω—Ç—ã\\Data\\Work\\workenv\\lib\\site-packages\\transformers\\generation\\utils.py:1288: UserWarning: Using `max_length`'s default (4) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9121322822534128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mytre\\OneDrive\\–î–æ–∫—É–º–µ–Ω—Ç—ã\\Data\\Work\\workenv\\lib\\site-packages\\transformers\\generation\\utils.py:1288: UserWarning: Using `max_length`'s default (4) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9132297803963578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mytre\\OneDrive\\–î–æ–∫—É–º–µ–Ω—Ç—ã\\Data\\Work\\workenv\\lib\\site-packages\\transformers\\generation\\utils.py:1288: UserWarning: Using `max_length`'s default (4) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.913681053157807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mytre\\OneDrive\\–î–æ–∫—É–º–µ–Ω—Ç—ã\\Data\\Work\\workenv\\lib\\site-packages\\transformers\\generation\\utils.py:1288: UserWarning: Using `max_length`'s default (4) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9125136697391033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mytre\\OneDrive\\–î–æ–∫—É–º–µ–Ω—Ç—ã\\Data\\Work\\workenv\\lib\\site-packages\\transformers\\generation\\utils.py:1288: UserWarning: Using `max_length`'s default (4) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9123658285546243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mytre\\OneDrive\\–î–æ–∫—É–º–µ–Ω—Ç—ã\\Data\\Work\\workenv\\lib\\site-packages\\transformers\\generation\\utils.py:1288: UserWarning: Using `max_length`'s default (4) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9122344118872379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mytre\\OneDrive\\–î–æ–∫—É–º–µ–Ω—Ç—ã\\Data\\Work\\workenv\\lib\\site-packages\\transformers\\generation\\utils.py:1288: UserWarning: Using `max_length`'s default (4) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9125115116432049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mytre\\OneDrive\\–î–æ–∫—É–º–µ–Ω—Ç—ã\\Data\\Work\\workenv\\lib\\site-packages\\transformers\\generation\\utils.py:1288: UserWarning: Using `max_length`'s default (4) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9136357955255593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mytre\\OneDrive\\–î–æ–∫—É–º–µ–Ω—Ç—ã\\Data\\Work\\workenv\\lib\\site-packages\\transformers\\generation\\utils.py:1288: UserWarning: Using `max_length`'s default (4) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9135817164623259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mytre\\OneDrive\\–î–æ–∫—É–º–µ–Ω—Ç—ã\\Data\\Work\\workenv\\lib\\site-packages\\transformers\\generation\\utils.py:1288: UserWarning: Using `max_length`'s default (4) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9121690716963982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mytre\\OneDrive\\–î–æ–∫—É–º–µ–Ω—Ç—ã\\Data\\Work\\workenv\\lib\\site-packages\\transformers\\generation\\utils.py:1288: UserWarning: Using `max_length`'s default (4) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9120747744810347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mytre\\OneDrive\\–î–æ–∫—É–º–µ–Ω—Ç—ã\\Data\\Work\\workenv\\lib\\site-packages\\transformers\\generation\\utils.py:1288: UserWarning: Using `max_length`'s default (4) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9108426205603583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mytre\\OneDrive\\–î–æ–∫—É–º–µ–Ω—Ç—ã\\Data\\Work\\workenv\\lib\\site-packages\\transformers\\generation\\utils.py:1288: UserWarning: Using `max_length`'s default (4) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9107089291070893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mytre\\OneDrive\\–î–æ–∫—É–º–µ–Ω—Ç—ã\\Data\\Work\\workenv\\lib\\site-packages\\transformers\\generation\\utils.py:1288: UserWarning: Using `max_length`'s default (4) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9108739544274589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mytre\\OneDrive\\–î–æ–∫—É–º–µ–Ω—Ç—ã\\Data\\Work\\workenv\\lib\\site-packages\\transformers\\generation\\utils.py:1288: UserWarning: Using `max_length`'s default (4) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9113970928617721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mytre\\OneDrive\\–î–æ–∫—É–º–µ–Ω—Ç—ã\\Data\\Work\\workenv\\lib\\site-packages\\transformers\\generation\\utils.py:1288: UserWarning: Using `max_length`'s default (4) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9117935898580484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mytre\\OneDrive\\–î–æ–∫—É–º–µ–Ω—Ç—ã\\Data\\Work\\workenv\\lib\\site-packages\\transformers\\generation\\utils.py:1288: UserWarning: Using `max_length`'s default (4) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9118179467287303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mytre\\OneDrive\\–î–æ–∫—É–º–µ–Ω—Ç—ã\\Data\\Work\\workenv\\lib\\site-packages\\transformers\\generation\\utils.py:1288: UserWarning: Using `max_length`'s default (4) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9120906591117407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mytre\\OneDrive\\–î–æ–∫—É–º–µ–Ω—Ç—ã\\Data\\Work\\workenv\\lib\\site-packages\\transformers\\generation\\utils.py:1288: UserWarning: Using `max_length`'s default (4) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9117006693008628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mytre\\OneDrive\\–î–æ–∫—É–º–µ–Ω—Ç—ã\\Data\\Work\\workenv\\lib\\site-packages\\transformers\\generation\\utils.py:1288: UserWarning: Using `max_length`'s default (4) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9118818842277947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mytre\\OneDrive\\–î–æ–∫—É–º–µ–Ω—Ç—ã\\Data\\Work\\workenv\\lib\\site-packages\\transformers\\generation\\utils.py:1288: UserWarning: Using `max_length`'s default (4) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9122036209378077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mytre\\OneDrive\\–î–æ–∫—É–º–µ–Ω—Ç—ã\\Data\\Work\\workenv\\lib\\site-packages\\transformers\\generation\\utils.py:1288: UserWarning: Using `max_length`'s default (4) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9119182413057864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mytre\\OneDrive\\–î–æ–∫—É–º–µ–Ω—Ç—ã\\Data\\Work\\workenv\\lib\\site-packages\\transformers\\generation\\utils.py:1288: UserWarning: Using `max_length`'s default (4) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9121491322048425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mytre\\OneDrive\\–î–æ–∫—É–º–µ–Ω—Ç—ã\\Data\\Work\\workenv\\lib\\site-packages\\transformers\\generation\\utils.py:1288: UserWarning: Using `max_length`'s default (4) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9122977571002013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mytre\\OneDrive\\–î–æ–∫—É–º–µ–Ω—Ç—ã\\Data\\Work\\workenv\\lib\\site-packages\\transformers\\generation\\utils.py:1288: UserWarning: Using `max_length`'s default (4) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9126410377677184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mytre\\OneDrive\\–î–æ–∫—É–º–µ–Ω—Ç—ã\\Data\\Work\\workenv\\lib\\site-packages\\transformers\\generation\\utils.py:1288: UserWarning: Using `max_length`'s default (4) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9121110453259654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mytre\\OneDrive\\–î–æ–∫—É–º–µ–Ω—Ç—ã\\Data\\Work\\workenv\\lib\\site-packages\\transformers\\generation\\utils.py:1288: UserWarning: Using `max_length`'s default (4) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9118646240625601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mytre\\OneDrive\\–î–æ–∫—É–º–µ–Ω—Ç—ã\\Data\\Work\\workenv\\lib\\site-packages\\transformers\\generation\\utils.py:1288: UserWarning: Using `max_length`'s default (4) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.911755515280295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mytre\\OneDrive\\–î–æ–∫—É–º–µ–Ω—Ç—ã\\Data\\Work\\workenv\\lib\\site-packages\\transformers\\generation\\utils.py:1288: UserWarning: Using `max_length`'s default (4) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.911755515280295\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the device to run the evaluation on\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "model.to(device)\n",
    "# Evaluate the model on the eval dataset\n",
    "y_true = []\n",
    "y_pred = []\n",
    "xx = []\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(len(eval_dataset)), nrows=2):\n",
    "        url = eval_df['file_name'][i]\n",
    "        xx.append(url)\n",
    "        target_text = int(eval_df['text'][i])\n",
    "        image = Image.open(url).convert(\"RGB\")   \n",
    "\n",
    "        pixel_values = processor(image, return_tensors=\"pt\").pixel_values\n",
    "        generated_ids = model.generate(pixel_values.cuda(), max_new_tokens=3)\n",
    "\n",
    "        generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "        #pixel_values = batch['pixel_values']\n",
    "        #generated_ids = model.generate(pixel_values.cuda())       \n",
    "\n",
    "        # Make a prediction\n",
    "        #generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "        x = []        \n",
    "        if generated_text.isdigit():\n",
    "            x.append(int(generated_text))\n",
    "        else:\n",
    "            x.append(1000)    \n",
    "\n",
    "        # Save the true and predicted labels\n",
    "        y_true.append(target_text)\n",
    "        y_pred.append(x)\n",
    "\n",
    "        if (i % 400  == 0) & (i > 2):\n",
    "            accuracy = accuracy_score(y_true, y_pred)\n",
    "            print(\"Accuracy:\", accuracy) \n",
    "\n",
    "print(\"Accuracy:\", accuracy)                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
